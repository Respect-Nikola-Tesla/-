% \maketitle

\begin{abstractskor}
	% \addcontentsline{toc}{section}{초록}  %%% TOC에 표시
	\noindent{
		본 보고서는 정보 엔트로피에 대한 탐구로 여러 제약 조건이 걸려있는 경우의 정보 엔트로피를 최대화시키는 확률 분포를 이론적으로 탐색하고 시뮬레이션을 통해 이를 검증하는 것을 목표로 한다. 정보 엔트로피는 통계역학에서 특정 사건이 생길 수 있는 평균적인 로그확률로 계산된다. 이는 열역학적으로 정의된 두 엔트로피와 상통하며 열역학 제 2법칙에서도 볼 수 있듯이 계는 항상 엔트로피가 최대인 상태를 점유한다. 이는 엔트로피가 최대인 상황을 점유할 확률이 높다는 것으로 정보 엔트로피의 경우 주어진 조건에 대해서 평균 정보량이 최대인 조건을 탐색한다는 의미이다.
        제약조건은 총 확률의 합이 1, 기댓값이 주어진 경우, 표준편차가 주어진 경우로 3가지가 있으며 라그랑주 승수법을 이용하여 확률분포가 취해야 할 조건을 구한다. 총 확률이 1인 경우에는 균일 분포가 최대였으며 기댓값이 주어진 경우에는 볼츠만 분포, 표준편차가 주어진 경우에는 정규 분포가 최대였다. 이는 연속 확장을 할 경우 관련 상수를 쉽게 찾을 수 있으나 이산 확률 분포로 취급하는 순간 관련 상수를 찾기 어려웠으며 시뮬레이션을 통해 주어진 원리와 상통하는지 확인하였다.
        시뮬레이션 기법은 최적화 기법 중 하나인 유전 알고리즘이다. $n=20$인 상황에 대해서 $p_1, p_2, \cdots p_n$을 유전자로 취급하며 관련 연산을 정의하고 $H(p)$가 최대인 분포를 탐색하였다. 그 결과는 이론 분석한 결과와 일치하였으며 kullback-leibler divergence를 이용하여 차이를 비교하였다.

	}
\end{abstractskor}






